<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time AI Chat System - Zach Zhang</title>
    <meta name="description" content="Multi-modal conversational AI system with emotion recognition and real-time processing">
    <!-- 主题预加载脚本 - 防止页面跳转时的频闪 -->
    <script>
    (function() {
        const savedTheme = localStorage.getItem('theme') || 'light';
        document.documentElement.setAttribute('data-theme', savedTheme);
    })();
    </script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- 导航栏 -->
    <nav class="navbar">
        <div class="nav-brand">Zach's Portfolio</div>
        <div class="nav-links">
            <a href="index.html" class="nav-link">Home</a>
            <a href="projects.html" class="nav-link">Projects</a>
            <a href="blog.html" class="nav-link">Blog</a>
            <a href="about.html" class="nav-link">About</a>
            <button class="theme-toggle" id="theme-toggle">
                <span class="material-icons">light_mode</span>
            </button>
        </div>
        <div class="nav-toggle" id="nav-toggle">
            <span class="material-icons">menu</span>
        </div>
    </nav>

    <nav class="breadcrumb">
      <a href="index.html" class="breadcrumb-link">Home</a>
      <span class="material-icons breadcrumb-separator">chevron_right</span>
      <a href="projects.html" class="breadcrumb-link">Projects</a>
      <span class="material-icons breadcrumb-separator">chevron_right</span>
      <span class="breadcrumb-current">Real-time AI Chat System</span>
    </nav>

    <!-- 主要内容区域 -->
    <main class="project-detail-container">
        <header class="project-detail-header">
            <div class="project-detail-intro">
                <h1>Real-time AI Chat System</h1>
                <p class="project-subtitle">Multi-modal Conversational AI with Emotion Recognition</p>
                <div class="project-meta">
                    <span class="project-location">Real-time Platform</span>
                    <span class="project-period">2023 - 2024</span>
                </div>
            </div>
            <div class="project-stats-overview">
                <div class="stat-item">
                    <span class="stat-number">10k+</span>
                    <span class="stat-label">Concurrent Users</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">92%</span>
                    <span class="stat-label">Emotion Accuracy</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">&lt;50ms</span>
                    <span class="stat-label">Latency</span>
                </div>
            </div>
        </header>

        <section class="project-detail-content">
            <div class="project-section">
                <h2>Project Overview</h2>
                <p>
                    The Real-time AI Chat System is a sophisticated conversational AI platform that combines 
                    natural language processing, emotion recognition, and real-time communication capabilities. 
                    Built to handle thousands of concurrent users with sub-50ms latency, the system provides 
                    intelligent, context-aware responses with emotional intelligence.
                </p>
                <p>
                    The platform supports multiple modalities including text, voice, and image inputs, 
                    making it suitable for various applications from customer service to educational 
                    assistance and entertainment.
                </p>
            </div>

            <div class="project-section">
                <h2>Technical Approach</h2>
                <div class="approach-grid">
                    <div class="approach-item">
                        <span class="material-icons">chat</span>
                        <h3>Multi-modal AI</h3>
                        <p>Integrated text, voice, and image processing capabilities with unified response generation.</p>
                    </div>
                    <div class="approach-item">
                        <span class="material-icons">psychology</span>
                        <h3>Emotion Recognition</h3>
                        <p>Advanced emotion detection with 92% accuracy using facial expression and voice tone analysis.</p>
                    </div>
                    <div class="approach-item">
                        <span class="material-icons">speed</span>
                        <h3>Real-time Processing</h3>
                        <p>WebSocket-based architecture with optimized message routing for sub-50ms response times.</p>
                    </div>
                    <div class="approach-item">
                        <span class="material-icons">scalability</span>
                        <h3>High Concurrency</h3>
                        <p>Horizontal scaling architecture supporting 10,000+ concurrent users with load balancing.</p>
                    </div>
                </div>
            </div>

            <div class="project-section">
                <h2>Technology Stack</h2>
                <div class="tech-stack-grid">
                    <div class="tech-category">
                        <h3>AI/ML</h3>
                        <div class="tech-tags">
                            <span class="tech-tag">OpenAI API</span>
                            <span class="tech-tag">NLP Models</span>
                            <span class="tech-tag">Computer Vision</span>
                            <span class="tech-tag">Speech Recognition</span>
                        </div>
                    </div>
                    <div class="tech-category">
                        <h3>Real-time</h3>
                        <div class="tech-tags">
                            <span class="tech-tag">WebSocket</span>
                            <span class="tech-tag">Socket.io</span>
                            <span class="tech-tag">Redis</span>
                            <span class="tech-tag">Message Queue</span>
                        </div>
                    </div>
                    <div class="tech-category">
                        <h3>Frontend</h3>
                        <div class="tech-tags">
                            <span class="tech-tag">React</span>
                            <span class="tech-tag">TypeScript</span>
                            <span class="tech-tag">WebRTC</span>
                            <span class="tech-tag">Canvas API</span>
                        </div>
                    </div>
                    <div class="tech-category">
                        <h3>Backend</h3>
                        <div class="tech-tags">
                            <span class="tech-tag">Node.js</span>
                            <span class="tech-tag">MongoDB</span>
                            <span class="tech-tag">Docker</span>
                            <span class="tech-tag">Kubernetes</span>
                        </div>
                    </div>
                </div>
            </div>

            <div class="project-section">
                <h2>Key Results</h2>
                <div class="results-grid">
                    <div class="result-item">
                        <div class="result-header">
                            <span class="material-icons">people</span>
                            <h3>Concurrent Users</h3>
                        </div>
                        <p>Successfully scaled to support 10,000+ concurrent users with stable performance and low latency.</p>
                        <div class="result-metrics">
                            <span class="metric">Peak: 12,500</span>
                            <span class="metric">Average: 8,200</span>
                        </div>
                    </div>
                    <div class="result-item">
                        <div class="result-header">
                            <span class="material-icons">psychology</span>
                            <h3>Emotion Recognition</h3>
                        </div>
                        <p>92% accuracy in emotion detection across text, voice, and facial expressions.</p>
                        <div class="result-metrics">
                            <span class="metric">Text: 89%</span>
                            <span class="metric">Voice: 94%</span>
                        </div>
                    </div>
                    <div class="result-item">
                        <div class="result-header">
                            <span class="material-icons">speed</span>
                            <h3>Response Latency</h3>
                        </div>
                        <p>Achieved sub-50ms average response time with 95th percentile under 100ms.</p>
                        <div class="result-metrics">
                            <span class="metric">Average: 45ms</span>
                            <span class="metric">P95: 95ms</span>
                        </div>
                    </div>
                    <div class="result-item">
                        <div class="result-header">
                            <span class="material-icons">satisfaction</span>
                            <h3>User Satisfaction</h3>
                        </div>
                        <p>High user satisfaction scores with 4.7/5 rating and 85% user retention rate.</p>
                        <div class="result-metrics">
                            <span class="metric">Rating: 4.7/5</span>
                            <span class="metric">Retention: 85%</span>
                        </div>
                    </div>
                </div>
            </div>

            <div class="project-section">
                <h2>System Features</h2>
                <div class="impact-grid">
                    <div class="impact-item">
                        <h3>Multi-modal Input</h3>
                        <p>Support for text, voice, and image inputs with unified processing pipeline.</p>
                    </div>
                    <div class="impact-item">
                        <h3>Emotion Intelligence</h3>
                        <p>Real-time emotion detection and response adaptation based on user emotional state.</p>
                    </div>
                    <div class="impact-item">
                        <h3>Context Awareness</h3>
                        <p>Maintains conversation context across multiple turns and sessions.</p>
                    </div>
                    <div class="impact-item">
                        <h3>Personalization</h3>
                        <p>Learns user preferences and adapts responses accordingly over time.</p>
                    </div>
                </div>
            </div>

            <div class="project-section">
                <h2>Challenges & Solutions</h2>
                <div class="challenges-grid">
                    <div class="challenge-item">
                        <h3>Challenge: Real-time Scalability</h3>
                        <p>Traditional HTTP-based systems couldn't handle thousands of concurrent connections.</p>
                        <h4>Solution:</h4>
                        <p>Implemented WebSocket-based architecture with Redis pub/sub for message distribution and horizontal scaling.</p>
                    </div>
                    <div class="challenge-item">
                        <h3>Challenge: Emotion Recognition Accuracy</h3>
                        <p>Multi-modal emotion detection required high accuracy across different input types.</p>
                        <h4>Solution:</h4>
                        <p>Developed ensemble model combining text sentiment analysis, voice emotion detection, and facial expression recognition.</p>
                    </div>
                    <div class="challenge-item">
                        <h3>Challenge: Response Quality</h3>
                        <p>Real-time constraints limited the complexity of AI models that could be used.</p>
                        <h4>Solution:</h4>
                        <p>Implemented hybrid approach with lightweight models for real-time responses and heavy models for complex queries.</p>
                    </div>
                </div>
            </div>
        </section>

        <aside class="project-sidebar">
            <div class="sidebar-section">
                <h3>Project Links</h3>
                <div class="project-links">
                    <a href="#" class="project-link">
                        <span class="material-icons">code</span>
                        GitHub Repository
                    </a>
                    <a href="#" class="project-link">
                        <span class="material-icons">article</span>
                        Technical Paper
                    </a>
                    <a href="#" class="project-link">
                        <span class="material-icons">play_circle</span>
                        Live Demo
                    </a>
                </div>
            </div>

            <div class="sidebar-section">
                <h3>Supported Modalities</h3>
                <div class="modality-list">
                    <div class="modality-item">
                        <span class="material-icons">text_fields</span>
                        <span>Text Chat</span>
                    </div>
                    <div class="modality-item">
                        <span class="material-icons">mic</span>
                        <span>Voice Input</span>
                    </div>
                    <div class="modality-item">
                        <span class="material-icons">image</span>
                        <span>Image Analysis</span>
                    </div>
                    <div class="modality-item">
                        <span class="material-icons">videocam</span>
                        <span>Video Chat</span>
                    </div>
                </div>
            </div>

            <div class="sidebar-section">
                <h3>Timeline</h3>
                <div class="timeline">
                    <div class="timeline-item">
                        <span class="timeline-date">May 2023</span>
                        <span class="timeline-event">Project Start</span>
                    </div>
                    <div class="timeline-item">
                        <span class="timeline-date">Aug 2023</span>
                        <span class="timeline-event">MVP Release</span>
                    </div>
                    <div class="timeline-item">
                        <span class="timeline-date">Nov 2023</span>
                        <span class="timeline-event">Beta Launch</span>
                    </div>
                    <div class="timeline-item">
                        <span class="timeline-date">Feb 2024</span>
                        <span class="timeline-event">Production</span>
                    </div>
                </div>
            </div>
        </aside>
    </main>

    <script src="main.js"></script>
    <footer class="footer">© 2025 Zach Zhang • Northeastern University</footer>
</body>
</html> 